import streamlit as st
import google.generativeai as genai
from PIL import Image
import PyPDF2
import docx
import json
import pandas as pd
from gtts import gTTS
import io
import graphviz
from youtube_transcript_api import YouTubeTranscriptApi

# --- 1. Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØµÙØ­Ø© ---
st.set_page_config(page_title="Ø§Ù„Ù…Ø¯Ø±Ø³ Ø§Ù„Ø´Ø§Ù…Ù„ (Unlimited)", page_icon="ğŸ›¡ï¸", layout="wide")

# --- 2. Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù…ÙØªØ§Ø­ ---
if "GOOGLE_API_KEY" in st.secrets:
    api_key = st.secrets["GOOGLE_API_KEY"]
else:
    api_key = "AIzaSyDDvLq3YjF9IrgWY51mD2RCHU2b7JF75Tk" 

genai.configure(api_key=api_key)
model = genai.GenerativeModel('gemini-2.0-flash')

# --- 3. Ø¯ÙˆØ§Ù„ Ø§Ù„Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ø°ÙƒÙŠØ© (Smart Readers) ---

def get_pdf_text(uploaded_file):
    try:
        pdf_reader = PyPDF2.PdfReader(uploaded_file)
        text = ""
        for page in pdf_reader.pages:
            text += page.extract_text() or ""
        return text
    except: return "[Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ù‚Ø±Ø§Ø¡Ø© Ù…Ù„Ù PDF]"

def get_docx_text(uploaded_file):
    try:
        doc = docx.Document(uploaded_file)
        full_text = []
        for para in doc.paragraphs:
            full_text.append(para.text)
        return '\n'.join(full_text)
    except: return "[Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ù‚Ø±Ø§Ø¡Ø© Ù…Ù„Ù Word]"

def get_excel_csv_text(uploaded_file):
    try:
        # Ù„Ùˆ Ø§ÙƒØ³ÙŠÙ„ Ø£Ùˆ CSV Ø¨Ù†Ø­ÙˆÙ„Ù‡ Ù„Ù†Øµ
        if uploaded_file.name.endswith('.csv'):
            df = pd.read_csv(uploaded_file)
        else:
            df = pd.read_excel(uploaded_file)
        return df.to_string() # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø¬Ø¯ÙˆÙ„ Ù„Ù†Øµ Ø¹Ø´Ø§Ù† Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ ÙŠÙÙ‡Ù…Ù‡
    except: return "[Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ù‚Ø±Ø§Ø¡Ø© Ù…Ù„Ù Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª]"

def read_any_text_file(uploaded_file):
    # Ø¯ÙŠ Ø§Ù„Ø¯Ø§Ù„Ø© Ø§Ù„Ø³Ø­Ø±ÙŠØ© Ù„Ø£ÙŠ Ù…Ù„Ù Ù†ØµÙŠ (ÙƒÙˆØ¯ØŒ txtØŒ jsonØŒ srt...)
    try:
        # Ø¨Ù†Ø­Ø§ÙˆÙ„ Ù†ÙÙƒ ØªØ´ÙÙŠØ± Ø§Ù„Ù…Ù„Ù Ø­ØªÙ‰ Ù„Ùˆ ÙÙŠÙ‡ Ø±Ù…ÙˆØ² ØºØ±ÙŠØ¨Ø© (errors='ignore')
        return uploaded_file.getvalue().decode("utf-8", errors='ignore')
    except: return "[Ù…Ù„Ù ØºÙŠØ± Ù‚Ø§Ø¨Ù„ Ù„Ù„Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù†ØµÙŠØ©]"

def clean_text(text):
    return text.replace("```json", "").replace("```graphviz", "").replace("```", "").strip()

def text_to_speech_html(text, lang='ar'):
    try:
        tts = gTTS(text=text, lang=lang)
        fp = io.BytesIO()
        tts.write_to_fp(fp)
        return fp
    except: return None

def get_youtube_text(video_url):
    try:
        video_id = video_url.split("v=")[1].split("&")[0]
        transcript = YouTubeTranscriptApi.get_transcript(video_id, languages=['ar', 'en'])
        full_text = " ".join([entry['text'] for entry in transcript])
        return full_text
    except: return None

# --- 4. Session State ---
if "messages" not in st.session_state: st.session_state.messages = []
if "file_content" not in st.session_state: st.session_state.file_content = ""
if "exam_history" not in st.session_state: st.session_state.exam_history = []
if "current_quiz" not in st.session_state: st.session_state.current_quiz = None
if "flashcards" not in st.session_state: st.session_state.flashcards = []

# --- 5. Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠØ© (ØªÙ… Ø¥Ù„ØºØ§Ø¡ Ø§Ù„Ù‚ÙŠÙˆØ¯ Ø¹Ù„Ù‰ Ù†ÙˆØ¹ Ø§Ù„Ù…Ù„ÙØ§Øª) ---
with st.sidebar:
    st.header("ğŸ›¡ï¸ Ù„ÙˆØ­Ø© Ø§Ù„ØªØ­ÙƒÙ…")
    mode = st.radio("Ø§Ù„ÙˆØ¶Ø¹:", 
                    ["ğŸ’¬ Ø§Ù„Ù…Ø°Ø§ÙƒØ±Ø© ÙˆØ§Ù„Ø´Ø§Øª", "ğŸ“º ÙŠÙˆØªÙŠÙˆØ¨", "ğŸ§  Ø®Ø±Ø§Ø¦Ø·", "ğŸƒ Ø¨Ø·Ø§Ù‚Ø§Øª", "ğŸ“ Ø§Ø®ØªØ¨Ø§Ø±", "ğŸ“Š ØªÙ‚ÙŠÙŠÙ…"])
    
    st.divider()
    
    if mode != "ğŸ“º ÙŠÙˆØªÙŠÙˆØ¨":
        st.subheader("ğŸ“‚ Ø§Ø±ÙØ¹ Ø£ÙŠ Ù…Ù„Ù ÙÙŠ Ø§Ù„Ø¯Ù†ÙŠØ§")
        # Ø§Ù„ØªØ¹Ø¯ÙŠÙ„ Ø§Ù„Ø³Ø­Ø±ÙŠ: Ø´Ù„Ù†Ø§ type=... Ø¹Ø´Ø§Ù† ÙŠÙ‚Ø¨Ù„ ÙƒÙ„Ù‡
        uploaded_files = st.file_uploader("Drop any file here", accept_multiple_files=True)
        
        if uploaded_files and st.button("ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ù„ÙØ§Øª ğŸš€"):
            with st.spinner("Ø¬Ø§Ø±ÙŠ ÙÙƒ Ø´ÙØ±Ø© Ø§Ù„Ù…Ù„ÙØ§Øª..."):
                combined_text = ""
                file_count = 0
                
                # Ø­Ù„Ù‚Ø© ØªÙƒØ±Ø§Ø±ÙŠØ© Ø°ÙƒÙŠØ© Ø¨ØªØ´ÙˆÙ Ù†ÙˆØ¹ Ø§Ù„Ù…Ù„Ù ÙˆØªØ®ØªØ§Ø± Ø§Ù„Ø£Ø¯Ø§Ø© Ø§Ù„Ù…Ù†Ø§Ø³Ø¨Ø©
                for file in uploaded_files:
                    try:
                        file_text = ""
                        fname = file.name.lower()
                        combined_text += f"\n\n--- Ù…Ù„Ù: {file.name} ---\n"
                        
                        # ØªÙˆØ¬ÙŠÙ‡ Ø§Ù„Ù…Ù„ÙØ§Øª Ù„Ù„Ø£Ø¯ÙˆØ§Øª Ø§Ù„Ù…Ù†Ø§Ø³Ø¨Ø©
                        if fname.endswith('.pdf'):
                            file_text = get_pdf_text(file)
                        elif fname.endswith('.docx'):
                            file_text = get_docx_text(file)
                        elif fname.endswith(('.xlsx', '.xls', '.csv')):
                            file_text = get_excel_csv_text(file)
                        elif fname.endswith(('.png', '.jpg', '.jpeg', '.webp')):
                            try:
                                image = Image.open(file)
                                res = model.generate_content(["Ø§Ø³ØªØ®Ø±Ø¬ ÙƒÙ„ Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ù…ÙƒØªÙˆØ¨Ø© ÙÙŠ Ø§Ù„ØµÙˆØ±Ø©", image])
                                file_text = res.text
                            except: file_text = "[ØµÙˆØ±Ø© ØºÙŠØ± ØµØ§Ù„Ø­Ø©]"
                        else:
                            # Ù„Ø£ÙŠ Ù…Ù„Ù ØªØ§Ù†ÙŠ (txt, py, java, html, json...)
                            file_text = read_any_text_file(file)
                        
                        combined_text += file_text
                        file_count += 1
                        
                    except Exception as e:
                        # Ù„Ùˆ Ù…Ù„Ù Ø¶Ø±Ø¨ØŒ Ù†ÙƒØªØ¨ Ø§Ø³Ù…Ù‡ ÙˆÙ†ÙƒÙ…Ù„ Ø¹Ø§Ø¯ÙŠ Ù…Ù† ØºÙŠØ± Ù…Ø§ Ø§Ù„Ø¨Ø±Ù†Ø§Ù…Ø¬ ÙŠÙ‚Ø¹
                        combined_text += f"\n[ÙØ´Ù„ Ù‚Ø±Ø§Ø¡Ø© Ù‡Ø°Ø§ Ø§Ù„Ù…Ù„Ù: {str(e)}]\n"
                
                st.session_state.file_content = combined_text
                if file_count > 0:
                    st.success(f"ØªÙ…Øª Ù‚Ø±Ø§Ø¡Ø© {file_count} Ù…Ù„ÙØ§Øª Ø¨Ù†Ø¬Ø§Ø­! Ù…Ù‡Ù…Ø§ ÙƒØ§Ù† Ù†ÙˆØ¹Ù‡Ù….")
                else:
                    st.warning("Ù„Ù… ÙŠØªÙ… Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù†ØµÙˆØµ Ù…ÙÙŠØ¯Ø©.")

# --- 6. Ø¨Ø§Ù‚ÙŠ Ø§Ù„Ø£ÙˆØ¶Ø§Ø¹ (Ø²ÙŠ Ù…Ø§ Ù‡ÙŠ) ---

if mode == "ğŸ’¬ Ø§Ù„Ù…Ø°Ø§ÙƒØ±Ø© ÙˆØ§Ù„Ø´Ø§Øª":
    st.title("ğŸ’¬ Ø§Ù„Ø´Ø§Øª Ø§Ù„Ù…Ø¯Ø±Ø¹")
    if not st.session_state.file_content: st.info("Ø§Ø±ÙØ¹ Ø£ÙŠ Ù…Ù„Ù (Excel, Word, Code...) ğŸ‘ˆ")
    else:
        for msg in st.session_state.messages:
            with st.chat_message(msg["role"]): st.markdown(msg["content"])
        if prompt := st.chat_input("Ø§ÙƒØªØ¨ Ø³Ø¤Ø§Ù„Ùƒ..."):
            st.session_state.messages.append({"role": "user", "content": prompt})
            with st.chat_message("user"): st.markdown(prompt)
            with st.chat_message("assistant"):
                with st.spinner("Ø¨ÙŠØ­Ù„Ù„..."):
                    # Ù†Ø¸Ø§Ù… Ø£Ù…Ø§Ù† Ø¹Ø´Ø§Ù† Ù„Ùˆ Ø§Ù„Ù†Øµ ÙƒØ¨ÙŠØ± Ø¬Ø¯Ø§Ù‹
                    content_snippet = st.session_state.file_content[:30000] 
                    full_prompt = f"Ø§Ù„Ù…Ø­ØªÙˆÙ‰:\n{content_snippet}\n\nØ³Ø¤Ø§Ù„: {prompt}\nØ¬Ø§ÙˆØ¨ Ø¨Ø§Ø­ØªØ±Ø§ÙÙŠØ©."
                    try:
                        response = model.generate_content(full_prompt)
                        st.markdown(response.text)
                        st.session_state.messages.append({"role": "assistant", "content": response.text})
                    except Exception as e:
                        st.error("Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ ÙˆØ§Ø¬Ù‡ Ù…Ø´ÙƒÙ„Ø© Ø¨Ø³ÙŠØ·Ø©ØŒ Ø­Ø§ÙˆÙ„ ØªØ³Ø£Ù„ Ø¨ØµÙŠØºØ© ØªØ§Ù†ÙŠØ©.")

elif mode == "ğŸ“º ÙŠÙˆØªÙŠÙˆØ¨":
    st.title("ğŸ“º ÙŠÙˆØªÙŠÙˆØ¨")
    url = st.text_input("Ø§Ù„Ø±Ø§Ø¨Ø·:")
    if st.button("Ù„Ø®Øµ") and url:
        yt_text = get_youtube_text(url)
        if yt_text:
            res = model.generate_content(f"Ù„Ø®Øµ: {yt_text}")
            st.write(res.text)
            st.session_state.file_content = yt_text
        else: st.error("ÙÙŠØ¯ÙŠÙˆ Ø¨Ø¯ÙˆÙ† ØªØ±Ø¬Ù…Ø© Ø£Ùˆ Ø±Ø§Ø¨Ø· Ø®Ø·Ø£")

elif mode == "ğŸ§  Ø®Ø±Ø§Ø¦Ø·":
    st.title("ğŸ§  Ø®Ø±Ø§Ø¦Ø·")
    if st.button("Ø±Ø³Ù…") and st.session_state.file_content:
        res = model.generate_content(f"Create Graphviz DOT code for: {st.session_state.file_content[:5000]} inside graphviz block")
        try: st.graphviz_chart(clean_text(res.text))
        except: st.error("ØªØ¹Ø°Ø± Ø§Ù„Ø±Ø³Ù…")

elif mode == "ğŸƒ Ø¨Ø·Ø§Ù‚Ø§Øª":
    st.title("ğŸƒ Ø¨Ø·Ø§Ù‚Ø§Øª")
    if st.button("Ø¥Ù†Ø´Ø§Ø¡") and st.session_state.file_content:
        try:
            res = model.generate_content(f"Extract 5 terms JSON from: {st.session_state.file_content[:4000]} as [{{'term':'','definition':''}}]")
            st.session_state.flashcards = json.loads(clean_text(res.text))
        except: pass
    for c in st.session_state.flashcards: st.info(f"{c['term']}: {c['definition']}")

elif mode == "ğŸ“ Ø§Ø®ØªØ¨Ø§Ø±":
    st.title("ğŸ“ Ø§Ø®ØªØ¨Ø§Ø±")
    if st.button("Ø¬Ø¯ÙŠØ¯") and st.session_state.file_content:
        try:
            res = model.generate_content(f"Create 5 MCQ JSON from: {st.session_state.file_content[:5000]} as [{{'question':'','options':[],'answer':''}}]")
            st.session_state.current_quiz = json.loads(clean_text(res.text))
            st.rerun()
        except: pass
    if st.session_state.current_quiz:
        with st.form("q"):
            ans = {}
            for i,q in enumerate(st.session_state.current_quiz):
                st.write(q['question'])
                ans[i] = st.radio("", q['options'], key=i)
            if st.form_submit_button("ØªØµØ­ÙŠØ­"):
                sc = sum([1 for i,q in enumerate(st.session_state.current_quiz) if ans[i]==q['answer']])
                st.write(f"{sc}/5")
                st.session_state.exam_history.append({"Score": sc*20})

elif mode == "ğŸ“Š ØªÙ‚ÙŠÙŠÙ…":
    st.title("ğŸ“Š ØªÙ‚ÙŠÙŠÙ…")
    if st.session_state.exam_history: st.line_chart(pd.DataFrame(st.session_state.exam_history)['Score'])
